function [Y,Xf,Af] = annRhoOfExxEyyTheta_version2(X,~,~)
%ANNRHOOFEXXEYYTHETA_VERSION2 neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 13-May-2017 10:55:59.
% 
% [Y] = annRhoOfExxEyyTheta_version2(X,~,~) takes these arguments:
% 
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = 3xQ matrix, input #1 at timestep ts.
% 
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 1xQ matrix, output #1 at timestep ts.
% 
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [269.87;0.0027219;1.18366025517735e-05];
x1_step1.gain = [2.00541200537892e-05;2.000840407432e-05;2.54662497959017];
x1_step1.ymin = -1;

% Layer 1
b1 = [0.71429009729484882474;0.22106926535784959809;1.7700745922244329744;5.1612396621633678251;-2.4472805057551987318;-8.6769801634393459722;4.1995038213433630858;-6.3205346134197180064;2.3313767281842796564;8.4191755414013300651];
IW1_1 = [-0.71681318581641673138 -4.6828593087693626273 2.9250412612089213837;-0.94417133514592554988 -0.25345803228304381038 0.24340206080214868423;-0.98492826328639315747 -2.4033849252023586907 -0.7975077636132535952;7.2833000665793701245 0.32162559240243482339 -4.2341792889702905001;0.3424825720499742876 -4.1345195007033410661 -1.6851140369323784896;-5.7945893398795744744 -5.4449479559206848123 -0.20748434517241656772;0.87241653262890161979 3.3228220247021553746 -0.62993961017764499299;-3.9448921828755572072 -2.9946568027815092528 -0.23772044650715742908;2.3189232883681336617 1.9214080492917173792 4.1780744782465379927;5.1718516741417719373 4.056014716724042124 0.25756932464847642761];

% Layer 2
b2 = -0.93930073922997003866;
LW2_1 = [-0.021533452700992807005 -0.22875207756482604515 -0.081938467042226528769 -0.070013039777462648949 -0.045350448639611136425 0.72053925234649507381 0.81652048074514282927 -5.1585485092320055855 0.02154046603690316572 -3.5786975235068596568];

% Output 1
y1_step1.ymin = -1;
y1_step1.gain = 2.22833777143939;
y1_step1.xoffset = 0.1;

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX, X = {X}; end;

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
  Q = size(X{1},2); % samples/series
else
  Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS

    % Input 1
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = repmat(b2,1,Q) + LW2_1*a1;
    
    % Output 1
    Y{1,ts} = mapminmax_reverse(a2,y1_step1);
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX, Y = cell2mat(Y); end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
  y = bsxfun(@minus,x,settings.xoffset);
  y = bsxfun(@times,y,settings.gain);
  y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
  a = 2 ./ (1 + exp(-2*n)) - 1;
end

% Map Minimum and Maximum Output Reverse-Processing Function
function x = mapminmax_reverse(y,settings)
  x = bsxfun(@minus,y,settings.ymin);
  x = bsxfun(@rdivide,x,settings.gain);
  x = bsxfun(@plus,x,settings.xoffset);
end
